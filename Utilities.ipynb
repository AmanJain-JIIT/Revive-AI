{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from srcnnModel.ipynb\n",
      "importing Jupyter notebook from vdsrcnnModel.ipynb\n",
      "importing Jupyter notebook from Utilities.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import import_ipynb\n",
    "import srcnnModel\n",
    "import vdsrcnnModel\n",
    "import Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffleDataset(arr1, arr2):\n",
    "    indices = np.random.permutation(len(arr1))\n",
    "    shuffled_array1 = arr1[indices]\n",
    "    shuffled_array2 = arr2[indices]\n",
    "    return shuffled_array1, shuffled_array2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processImage(image_input, size, normalizing, expand):\n",
    "    \"\"\"\n",
    "    Process an image from a file path or a cv2 image (NumPy array).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: The processed image.\n",
    "    \"\"\"\n",
    "    if isinstance(image_input, str):\n",
    "        image = cv2.imread(image_input)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image from path: {image_input}\")\n",
    "        \n",
    "    elif isinstance(image_input, np.ndarray):\n",
    "        image = image_input\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a file path (str) or a cv2 image (np.ndarray)\")\n",
    "\n",
    "    if size:\n",
    "        width = size[0]\n",
    "        height = size[1]\n",
    "        image = cv2.resize(image, (width, height))\n",
    "\n",
    "    if normalizing==1:\n",
    "        image = image.astype(np.float32) / 255.0\n",
    "        \n",
    "    elif normalizing==-1:\n",
    "        image = image.astype(np.float32) * 255.0\n",
    "        image=image.astype(np.uint8)\n",
    "    \n",
    "    if expand==1:\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(original, compressed, maxx = 1.0):\n",
    "    original = original.astype(np.float32)\n",
    "    compressed = compressed.astype(np.float32)\n",
    "    \n",
    "    mse = np.mean((original - compressed) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "\n",
    "    max_pixel = maxx\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    \n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(size, index):\n",
    "    dirName = \"LoadedData\\\\LoadedData(\" + str(size) + \")\"\n",
    "    hrName = dirName + \"\\\\\" + \"HR\"\n",
    "    lr2Name = dirName + \"\\\\\" + \"LR2\"\n",
    "\n",
    "    hr = os.listdir(hrName)\n",
    "    lr2 = os.listdir(lr2Name)\n",
    "\n",
    "    os.chdir(hrName)\n",
    "    hrData = np.load(hr[index])\n",
    "    os.chdir(\"A:\\WORK\\Projects\\Machine Learning\\Revive-AI\")\n",
    "\n",
    "    os.chdir(lr2Name)\n",
    "    lr2Data = np.load(lr2[index])\n",
    "    os.chdir(\"A:\\WORK\\Projects\\Machine Learning\\Revive-AI\")\n",
    "\n",
    "\n",
    "    return hrData, lr2Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validateModel(model, val_lr, val_hr, device):\n",
    "    if device==\"GPU\":\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            predictions = model.predict(val_lr)\n",
    "    else:\n",
    "        with tf.device(\"/CPU:0\"):\n",
    "            predictions = model.predict(val_lr)\n",
    "\n",
    "    originalPSNR = []\n",
    "    reconstructedPSNR = []\n",
    "\n",
    "    for i in range(len(predictions)):\n",
    "        predictedImage = predictions[i]\n",
    "        inputImage = processImage(val_lr[i], (val_hr.shape[1], val_hr.shape[2]), 0, 0)\n",
    "        originalImage = val_hr[i]\n",
    "        psnrOriginal = psnr(originalImage, inputImage)\n",
    "        psnrReconstructed = psnr(originalImage, predictedImage)\n",
    "        originalPSNR.append(psnrOriginal)\n",
    "        reconstructedPSNR.append(psnrReconstructed)\n",
    "\n",
    "    print(\"ORIGINAL IMAGE\\n\")\n",
    "    print(\"PSNR Range : \", min(originalPSNR), \"     -     \", max(originalPSNR), \"\\n\")\n",
    "    print(\"Mean PSNR : \", sum(originalPSNR)/len(originalPSNR))\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"RECONSTRUCTED IMAGE\\n\")\n",
    "    print(\"PSNR Range : \", min(reconstructedPSNR), \"     -     \", max(reconstructedPSNR), \"\\n\")\n",
    "    print(\"Mean PSNR : \", sum(reconstructedPSNR)/len(reconstructedPSNR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_gpu(memory_limit=None):\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            if memory_limit is not None:\n",
    "                tf.config.experimental.set_virtual_device_configuration(\n",
    "                    gpus[0],\n",
    "                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=memory_limit)]\n",
    "                )\n",
    "        except RuntimeError as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_gpu_availability(min_memory_mb=2048):\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Check memory details for each GPU\n",
    "            for gpu in gpus:\n",
    "                details = tf.config.experimental.get_device_details(gpu)\n",
    "                memory_limit = details.get('memory_limit', 0)\n",
    "                if memory_limit > min_memory_mb * 1024 * 1024:\n",
    "                    return True\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(iterState, dataBatch, epochs, b, device, modelType, modelPath, size):\n",
    "    for batch in range(0, dataBatch):\n",
    "        print(iterState)\n",
    "        print(\"\\n\")\n",
    "        print(\"Loading Batch \", batch+1, \" ....\")\n",
    "        hr, lr2 = Utilities.getData(size, batch)\n",
    "        hr, lr2= Utilities.shuffleDataset(hr, lr2)\n",
    "        train_hr, val_hr, train_lr, val_lr = train_test_split(hr, lr2, test_size=0.2, random_state=42)\n",
    "        print(\"Batch \", batch+1 , \" Loaded\\n\")\n",
    "\n",
    "        if os.path.exists(modelPath):\n",
    "            print(\"Loading Model For Batch \", batch+1)\n",
    "            if modelType==\"vdsrcnn\":\n",
    "                model = load_model(modelPath, custom_objects={'psnr': vdsrcnnModel.psnr})\n",
    "            else:\n",
    "                model = load_model(modelPath, custom_objects={'psnr': srcnnModel.psnr})\n",
    "            print(\"Model For Batch \", batch+1, \" Successfully Loaded\\n\")\n",
    "        else:\n",
    "            print(\"Building Model For Batch \", batch+1)\n",
    "            if modelType==\"vdsrcnn\":\n",
    "                model = vdsrcnnModel.build_vdsrcnn_model_LR2_HR(18, (size, size, 3))\n",
    "            else:\n",
    "                model = srcnnModel.build_srcnn_model_LR2_HR((size, size, 3))\n",
    "            print(\"Model For Batch \", batch+1, \" Successfully Built\\n\")\n",
    "        \n",
    "        if modelType==\"vdsrcnn\":\n",
    "            print(\"Training The Model On Batch \", batch+1)\n",
    "            vdsrcnnModel.trainModel(model, train_lr, train_hr, val_lr, val_hr, epochs=epochs, batch=b, device=device)\n",
    "            print(\"Model On Batch \", batch+1, \" Trained Successfully\\n\")\n",
    "        else:\n",
    "            print(\"Training The Model On Batch \", batch+1)\n",
    "            srcnnModel.trainModel(model, train_lr, train_hr, val_lr, val_hr, epochs=epochs, batch=b, device=device)\n",
    "            print(\"Model On Batch \", batch+1, \" Trained Successfully\\n\")\n",
    "\n",
    "        model.save(modelPath)\n",
    "\n",
    "        del hr, lr2, train_hr, train_lr, val_hr, val_lr, model\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(iterations, epochs, b, dataBatch, device, modelType, modelPath, size):\n",
    "    for i in range(iterations):\n",
    "        iterState = \"Running Iteration \" + str(i+1) + \" On Dataset Of \" + str(dataBatch) + \" Batches\"\n",
    "        trainer(iterState, dataBatch, epochs, b, device, modelType, modelPath, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(modelType, modelPath, batch, size):\n",
    "\n",
    "    if modelType==\"vdsrcnn\":\n",
    "        model = load_model(modelPath, custom_objects={'psnr': vdsrcnnModel.psnr})\n",
    "    else:\n",
    "        model = load_model(modelPath, custom_objects={'psnr': srcnnModel.psnr})\n",
    "\n",
    "    hr, lr2 = Utilities.getData(size, batch)\n",
    "    hr, lr2= Utilities.shuffleDataset(hr, lr2)\n",
    "    train_hr, val_hr, train_lr, val_lr = train_test_split(hr, lr2, test_size=0.2, random_state=42)\n",
    "\n",
    "    if Utilities.check_gpu_availability(8000):\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "            predictions = model.predict(val_lr)\n",
    "    else:\n",
    "        with tf.device(\"/CPU:0\"):\n",
    "            predictions = model.predict(val_lr)\n",
    "            \n",
    "    lowResPSNRs = []\n",
    "    reconstructedPSNRs = []\n",
    "\n",
    "    for index in range(len(predictions)):\n",
    "        lowResImage = val_lr[index]\n",
    "        reconstructedImage = predictions[index]\n",
    "        highResImage = val_hr[index]\n",
    "\n",
    "        psnrLowRes = psnr(lowResImage, highResImage)\n",
    "        psnrReconstructed = psnr(reconstructedImage, highResImage)\n",
    "\n",
    "        lowResPSNRs.append(psnrLowRes)\n",
    "        reconstructedPSNRs.append(psnrReconstructed)\n",
    "\n",
    "    return lowResPSNRs, reconstructedPSNRs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(batches, modelType, modelPath, size):\n",
    "    modelReport = {}\n",
    "    for batch in range(0, batches):\n",
    "        lowRes, reconstrucetd = Utilities.evaluateModel(modelType, modelPath, batch, size)\n",
    "        modelReport[batch+1] = [lowRes, reconstrucetd]\n",
    "    return modelReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeModelReport(modelReport):\n",
    "    batches = list(modelReport.keys())\n",
    "    low = []\n",
    "    rec = []\n",
    "    for batch in batches:\n",
    "        lowRes = modelReport[batch][0]\n",
    "        reconstructed = modelReport[batch][1]\n",
    "        lowPSNR = sum(lowRes)/len(lowRes)\n",
    "        reconstructedPSNR = sum(reconstructed)/len(reconstructed)\n",
    "        low.append(lowPSNR)\n",
    "        rec.append(reconstructedPSNR)\n",
    "\n",
    "        print(\"Results on batch \", batch)\n",
    "        print(\"                    Low Res Image     Reconstructed Image\")\n",
    "        print(\"Mininum PSNR       \", \"{:.2f}\".format(min(lowRes)), \"           \", \"{:.2f}\".format(min(reconstructed)))\n",
    "        print(\"Maximum PSNR       \", \"{:.2f}\".format(max(lowRes)), \"           \", \"{:.2f}\".format(max(reconstructed)))\n",
    "        print(\"Average PSNR       \", \"{:.2f}\".format(sum(lowRes)/len(lowRes)), \"           \", \"{:.2f}\".format(sum(reconstructed)/len(reconstructed)))\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Average PSNR of Low-Res Images : \", sum(low)/len(low))\n",
    "    print(\"Average PSNR of Reconstructed Images : \", sum(rec)/len(rec))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferOnLoadedData(modelType, modelPath, size, batches):\n",
    "\n",
    "    if modelType==\"vdsrcnn\":\n",
    "        model = load_model(modelPath, custom_objects={'psnr': vdsrcnnModel.psnr})\n",
    "    else:\n",
    "        model = load_model(modelPath, custom_objects={'psnr': srcnnModel.psnr})\n",
    "\n",
    "    count = 0\n",
    "    \n",
    "    for batch in range(0, batches):\n",
    "        hr, lr2 = Utilities.getData(size, batch)\n",
    "        hr, lr2= Utilities.shuffleDataset(hr, lr2)\n",
    "        train_hr, val_hr, train_lr, val_lr = train_test_split(hr, lr2, test_size=0.2, random_state=42)\n",
    "\n",
    "        del hr, lr2, train_hr, train_lr\n",
    "\n",
    "        index = random.randint(0, (len(val_hr)-1))\n",
    "\n",
    "        highResImage = val_hr[index]\n",
    "        lowResImage = val_lr[index]\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "                       reconstructedImage = model.predict(val_lr)[index]\n",
    "\n",
    "        lowPSNR = Utilities.psnr(highResImage, lowResImage, 1.0)\n",
    "        reconstructedPSNR = Utilities.psnr(highResImage, reconstructedImage, 1.0)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True, gridspec_kw={'hspace': 0.8})\n",
    "\n",
    "        if lowPSNR<reconstructedPSNR:\n",
    "                count+=1\n",
    "                fig.set_facecolor(\"lightgreen\")\n",
    "        else:\n",
    "                fig.set_facecolor(\"pink\")\n",
    "        \n",
    "        lowResImage = cv2.cvtColor(lowResImage, cv2.COLOR_BGR2RGB)\n",
    "        highResImage = cv2.cvtColor(highResImage, cv2.COLOR_BGR2RGB)\n",
    "        reconstructedImage = cv2.cvtColor(reconstructedImage, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        print(\"Batch \", str(batch+1), \" Of \", str(batches), \" Batches\")\n",
    "\n",
    "        axes[0].imshow(lowResImage)\n",
    "        axes[0].set_title('Low-Res Image', fontsize=15)\n",
    "        axes[0].set_xlabel('PSNR : ' + str(round(lowPSNR, 2)), fontsize=15)\n",
    "\n",
    "        axes[1].imshow(reconstructedImage)\n",
    "        axes[1].set_title('Reconstructed Image', fontsize=15)\n",
    "        axes[1].set_xlabel('PSNR : ' + str(round(reconstructedPSNR, 2)), fontsize=15)\n",
    "\n",
    "        axes[2].imshow(highResImage)\n",
    "        axes[2].set_title('High-Res Image', fontsize=15)\n",
    "        axes[2].set_xlabel('PSNR : INF', fontsize=15)\n",
    "    \n",
    "        plt.show()\n",
    "\n",
    "    accuracy = round((count/batches)*100, 2)\n",
    "    print(\"The Model Improved Image Resolution Of Random Images From \", count, \" Batches Out Of The \", batches, \" Batches.\\n\")\n",
    "    print(\"Model's Accuracy : \", str(accuracy) + \"%\")\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inferOnRawData(modelType, modelPath, size, samples, highResPath, lowResPath):\n",
    "\n",
    "    if modelType==\"vdsrcnn\":\n",
    "        model = load_model(modelPath, custom_objects={'psnr': vdsrcnnModel.psnr})\n",
    "    else:\n",
    "        model = load_model(modelPath, custom_objects={'psnr': srcnnModel.psnr})\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    highResImagePaths = os.listdir(highResPath)\n",
    "    lowResImagePaths = os.listdir(lowResPath)\n",
    "    \n",
    "    for sample in range(0, samples):\n",
    "        index = random.randint(0, (len(highResImagePaths)-1))\n",
    "\n",
    "        highResImagePath = highResPath + \"\\\\\" + highResImagePaths[index]\n",
    "        lowResImagePath = lowResPath + \"\\\\\" + lowResImagePaths[index]\n",
    "\n",
    "        highResImage = Utilities.processImage(highResImagePath, None, 1, 0)\n",
    "        width = highResImage.shape[1]\n",
    "        height = highResImage.shape[0]\n",
    "        lowResImage = Utilities.processImage(lowResImagePath, (width, height), 1, 0)\n",
    "\n",
    "        inputImage = Utilities.processImage(lowResImagePath, (size, size), 1, 1)\n",
    "        with tf.device(\"/GPU:0\"):\n",
    "                       reconstructedImage = model.predict(inputImage)[0]\n",
    "        \n",
    "        reconstructedImage = Utilities.processImage(reconstructedImage, (width, height), 0, 0)\n",
    "\n",
    "\n",
    "\n",
    "        lowPSNR = Utilities.psnr(highResImage, lowResImage, 1.0)\n",
    "        reconstructedPSNR = Utilities.psnr(highResImage, reconstructedImage, 1.0)\n",
    "\n",
    "        lowResImage = cv2.cvtColor(lowResImage, cv2.COLOR_BGR2RGB)\n",
    "        highResImage = cv2.cvtColor(highResImage, cv2.COLOR_BGR2RGB)\n",
    "        reconstructedImage = cv2.cvtColor(reconstructedImage, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 5), sharey=True, gridspec_kw={'hspace': 0.8})\n",
    "\n",
    "        if lowPSNR<reconstructedPSNR:\n",
    "                count+=1\n",
    "                fig.set_facecolor(\"lightgreen\")\n",
    "        else:\n",
    "                fig.set_facecolor(\"pink\")\n",
    "        \n",
    "        print(\"Batch \", str(sample+1), \" Of \", str(samples), \" Samples\")\n",
    "\n",
    "        axes[0].imshow(lowResImage)\n",
    "        axes[0].set_title('Low-Res Image', fontsize=15)\n",
    "        axes[0].set_xlabel('PSNR : ' + str(round(lowPSNR, 2)), fontsize=15)\n",
    "\n",
    "        axes[1].imshow(reconstructedImage)\n",
    "        axes[1].set_title('Reconstructed Image', fontsize=15)\n",
    "        axes[1].set_xlabel('PSNR : ' + str(round(reconstructedPSNR, 2)), fontsize=15)\n",
    "\n",
    "        axes[2].imshow(highResImage)\n",
    "        axes[2].set_title('High-Res Image', fontsize=15)\n",
    "        axes[2].set_xlabel('PSNR : INF', fontsize=15)\n",
    "    \n",
    "        plt.show()\n",
    "\n",
    "    accuracy = round((count/samples)*100, 2)\n",
    "    print(\"The Model Improved Image Resolution Of Random Images From \", count, \" Samples Out Of The \", samples, \" Samples.\\n\")\n",
    "    print(\"Model's Accuracy : \", str(accuracy) + \"%\")\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareInferenceData(inputDir, outputDir, size, start, end):\n",
    "    os.makedirs(outputDir, exist_ok=True)\n",
    "    images = os.listdir(inputDir)[start:end]\n",
    "    for image in images:\n",
    "        path = inputDir + \"\\\\\" + image\n",
    "        img = Utilities.processImage(path, (size, size), 0, 0)\n",
    "        savePath = outputDir + \"\\\\\" + image\n",
    "        cv2.imwrite(savePath, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
